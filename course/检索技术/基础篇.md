#### 倒排索引
- 底层实现是hash表, 将内容或者属性作为key来存储对应的文档列表, 使得我们在O(1)的时间复杂度完成查询。
- 通过分词技术切割词语, 拿到各自的posting list, 继而通过链表归并的过程完成多个key的联合查询。 

#### 测试
假设有个员工管理系统有ID、姓名、所属部门信息, 需要查询根据ID范围查询员工信息, 根据姓名查询员工信息, 根据部门查询部门里有哪些员工？

- 根据有序数组读取就行, 有序数组 

- 根据倒排索引, 姓名为key, 员工ID为posting list；

- 倒排索引:部门id为可以, 员工ID为posting list 

四个文件: 用户信息文件, 用户索引文件, 姓名倒排索引, 部门倒排索引

#### 联合查询优化
- 调整次序法、通过从小到大求交集
- 快速多路归并法 利用跳表快速跳过多个元素的能力结合优化多路归并方案, 提升posting list 归并性能。
- 预先组合法 将热门的key查询组合提前处理好, 作为单独可以保持好posting list
- 缓存法, 将临时的热点查询组合结果进行缓存, 避免重复查询每次都重复计算

#### 倒排索引加速
- 跳表来实现posting list。
- 哈希表加速倒排索引, 大表建立hash, 查询小表, 将经常使用的key的posting list存入哈希表。
- 位图法: hash之后存在位图中, 利用了其快速求交集的原理可以准备找到posting list
- roaring bitmap 则是由一个高16位的有序数组存数字（key）, 低16位作为下标, 存入bitmap（posting list）

#### B+树索引的快速索引

内存读写比磁盘快

- 内存是半导体，磁盘读取需要磁盘盘片旋转，读取速度在一万到百万级别数据差

块、簇

- 操作系统最小读写单位
- 一次性读取一个块

高效检索原则

- 对磁盘的访问次数要尽可能的少

如何解决二分法中有效数组的数据量大的问题

- 将磁盘数据用指针替换，实现数据和索引的分离
- 为了适应频繁变化，将有效数组替换为二叉查找树
  - 二叉查找树的中序遍历就是有序数组

如何理解B+树

- 结构
  - 内层节点存储key和磁盘数据指针pointer，用来维护树形结构；
  - 叶子节点存储 key和对应数据，用来访问数据。

- 设计
  - 将树的高度压缩，变成多叉平衡查找树，降低IO次数
  - 将一个叶子节点的大小设计成等于一个块的大小
    - 每次查找节点访问磁盘，拿到一个块的数据量，也就是一次IO，最大IO频次为树的高度
    - 还可以将内层节点读入内存，这样进一步降低IO

B+树如何动态调整自己

- 叶子节点的数据分裂
  - 生成新的叶子节点，将数据在两个节点中平分
  - 父节点未满，也要分裂
  - 内部节点调整完毕，进一步需要调整根节点，如果根节点未满，则修改

本章要点：

- 索引与数据分离，实现快速检索

#### Nosql检索：LSM树（Log Structured Merge Trees）

B+树为何不适合大数据写入场景

- B+树的数据都在叶子节点中，而叶子结点都在磁盘中
- 每次插入都要随机写磁盘，因此需要批量写

LSM机制：

- 先写内存
- 当数据达到阈值，以块为单位写入磁盘

如何保证批量写时系统崩溃可以恢复

- WAL预写日志技术（mysql中的redo日志也是这种机制）
  - 把对数据的修改先写入磁盘，追加写效率很高
  - 周期性地监测内存中的数据是否被处理完了
    - 用Check point记录对应删除或者写入磁盘日志，来保证log文件不会无线增长
  - 系统重启，只需要读取检查点，就能定位最后一次成功处理数据的位置

内存数据和磁盘数据的合并

- 滚动合并
  - 内存中的有序链表和磁盘上的有序链表进行合并，转化为归并问题
  - 详细过程，内存中的树为c0，磁盘上为c1
    1. 将 C1 树的当前叶子节点从前往后读入内存，叫做清空块
    2. 将 C0 树的叶子节点和清空块中的数据进行归并排序，写入内存的新块中，叫做填充块
    3. 填充块写满了，我们就要将填充块作为新的叶节点集合顺序写入磁盘，如果c0遍历完了就继续归并写入新块，否则就去加载清空块
    4. 重复第三步，直到全部写完磁盘

**LSM** 树是如何检索的

- 优先读取内存，命中，根据检查是否有删除标记来返回，如果没有命中，则去磁盘查找
- 删除，只会给内存的数据打上标记
- 合并，如果遇到删除标记则跳过不合并





